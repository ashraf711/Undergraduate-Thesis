{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CckqEcrxmGV"
      },
      "outputs": [],
      "source": [
        "#####CTRL+F and search for 'CTRL+START', to go to the starting cell block.\n",
        "#ALL THE EXPLANATION ARE COMMENTS IN CAPS LOCK\n",
        "\n",
        "#THIS CODE BLOCK MAKES SURE THAT THE NOTEBOOK HAS THE NECESSARY LIBRARIES. BY DEFAULT, EVERY SESSION IN COLAB IS A FRESH PYTHON\n",
        "# ENVIRONMENT, SO TO MAKE SURE THAT THE NECESSARY LIBRARIES ARE PRESENT THIS CODE BLOCK IS RUN\n",
        "#IVE MADE SURE THAT THE LIBRARIES WILL ONLY BE INSTALLED ONCE EVERY SESSION, RESTARTING THE NOTEBOOOK DOES NOT AFFECT IT.\n",
        "#MAKE SURE TO NEVER DISCONNECT AND DELETE RUNTIME, AS IT WILL REMOVE EVERY CUSTOM INSTALLATION OF THE LIBRARIES, AND CONNECT THE NOTEBOOK TO A FRESH\n",
        "#PYTHON INSTALLATION.\n",
        "\n",
        "from IPython.display import clear_output as clear,Image\n",
        "import json,os,time,tarfile,shutil,numpy as np, nibabel\n",
        "from glob import glob\n",
        "\n",
        "from nibabel import load,Nifti1Image,save\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "##############JUST PLOTTING\n",
        "\n",
        "try:\n",
        "  from humanfriendly import format_timespan, format_size\n",
        "except ModuleNotFoundError:\n",
        "  !pip install humanfriendly\n",
        "  from humanfriendly import format_timespan, format_size\n",
        "\n",
        "\n",
        "try:\n",
        "  import pydicom\n",
        "except ModuleNotFoundError:\n",
        "  !pip install pydicom\n",
        "  import pydicom\n",
        "\n",
        "\n",
        "try:\n",
        "  import dicom2nifti\n",
        "except ModuleNotFoundError:\n",
        "  !pip install dicom2nifti\n",
        "  import dicom2nifti\n",
        "\n",
        "\n",
        "try:\n",
        "  import SimpleITK as sitk\n",
        "except ModuleNotFoundError:\n",
        "  !pip install simpleitk\n",
        "  import SimpleITK as sitk\n",
        "\n",
        "\n",
        "try:\n",
        "  import wget\n",
        "except ModuleNotFoundError:\n",
        "  !pip install wget\n",
        "  import wget\n",
        "\n",
        "try:\n",
        "  import monai\n",
        "  from monai.transforms import(\n",
        "    Compose,\n",
        "    AddChanneld,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "  )\n",
        "  from monai.data import DataLoader, Dataset, CacheDataset\n",
        "  from monai.utils import set_determinism\n",
        "  from monai.utils import first\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "  !pip install monai\n",
        "  !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "  from monai.transforms import(\n",
        "    Compose,\n",
        "    AddChanneld,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        ")\n",
        "  from monai.data import DataLoader, Dataset, CacheDataset\n",
        "  from monai.utils import set_determinism\n",
        "  from monai.utils import first\n",
        "\n",
        "\n",
        "import numpy as np, nibabel\n",
        "from matplotlib import pyplot as plt\n",
        "from monai.transforms import(\n",
        "    Compose,\n",
        "    AddChanneld,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        ")\n",
        "from monai.data import DataLoader, Dataset, CacheDataset\n",
        "from monai.utils import set_determinism\n",
        "from monai.utils import first\n",
        "##############JUST PLOTTING\n",
        "\n",
        "#SOME IMPORTS\n",
        "\n",
        "\n",
        "import numpy as np, nibabel\n",
        "from matplotlib import pyplot as plt\n",
        "from monai.transforms import(\n",
        "  Compose,\n",
        "  AddChanneld,\n",
        "  LoadImaged,\n",
        "  Resized,\n",
        "  ToTensord,\n",
        "  Spacingd,\n",
        "  Orientationd,\n",
        "  ScaleIntensityRanged,\n",
        "  CropForegroundd,\n",
        ")\n",
        "from monai.data import DataLoader, Dataset, CacheDataset\n",
        "from monai.utils import set_determinism\n",
        "from monai.utils import first\n",
        "from monai.utils import first, set_determinism\n",
        "from monai.transforms import(\n",
        "    Compose,\n",
        "    AddChanneld,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    Activations,\n",
        ")\n",
        "\n",
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.data import CacheDataset, DataLoader, Dataset\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.utils import first\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from monai.losses import DiceLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "main_path = '/content/drive/MyDrive/thesis_dataset/'\n",
        "livpath = main_path+'Liver/Task03_Liver/'\n",
        "mypath = main_path+'test_path/'\n",
        "trpath = main_path+'imagesTr_path'\n",
        "labels = main_path+'labels_path'\n",
        "tspath = main_path+'imagesTs_path'\n",
        "folder = 'imagesTr'\n",
        "sixtyfournifties = main_path+'groups_of_64_nifti/'+folder+'/'\n",
        "\n",
        "separator = ' —— '\n",
        "sep = ' — '\n",
        "empty_list = ['',\"\",\" \",' ']\n",
        "\n",
        "main_path = '/content/drive/MyDrive/thesis_dataset/'\n",
        "livpath = main_path+'Liver/Task03_Liver/'\n",
        "mypath = main_path+'test_path/'\n",
        "\n",
        "trpath = main_path+'imagesTr_path'\n",
        "labels = main_path+'labels_path'\n",
        "tspath = main_path+'imagesTs_path'\n",
        "traindir = main_path+'TRAINER/'\n",
        "tsseg = traindir+'TestSegmentation/'\n",
        "tsvol = traindir+'TestVolumes/'\n",
        "trseg = traindir+'TrainSegmentation/'\n",
        "trvol = traindir+'TrainVolumes/'\n",
        "data_dir = traindir\n",
        "model_dir = main_path+'MODELscratch/'\n",
        "kfold = main_path+'KFold/'\n",
        "\n",
        "\n",
        "\n",
        "clear()\n",
        "my_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('CHOOSING',my_device,'to do the training')\n",
        "\n",
        "clear()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#EASE OF USE, THIS TO_JSON FUNCTION DUMPS ALL THE DICTONARY INTO A JSON FILE. THIS IS MAINLY FOR STORING DATA.\n",
        "## THE FUNCTION NAMES ARE SELF-EXPLANATORY\n",
        "\n",
        "def to_json(dic, name, string):\n",
        "  # print('to_json:',string,sep,name)c\n",
        "  path = main_path\n",
        "  a = 1\n",
        "  if string == 'write':\n",
        "\n",
        "    if dic == {}:\n",
        "      print('Given Dictionary is empty. Check again!!')\n",
        "      return False\n",
        "    if a == 1:\n",
        "\n",
        "      with open(path+name+'.json','w') as fp:\n",
        "        json.dump(dic,fp)\n",
        "    else:\n",
        "      print('Did not save anything.')\n",
        "      return False\n",
        "\n",
        "    # print('saved '+name+'.json')\n",
        "    print('saved',sep,name,'('+getfilesize(path+name+'.json',1)+')')\n",
        "\n",
        "  if string == 'read':\n",
        "    with open(path+name+'.json','r') as fp:\n",
        "      data = json.load(fp)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def getfilesize(the_file,the_type):\n",
        "  file_size = os.path.getsize(the_file)\n",
        "  actual_file_size = format_size(file_size)\n",
        "\n",
        "  la_output = the_file.split('/')[-1]+sep+actual_file_size\n",
        "\n",
        "  if the_type not in empty_list:\n",
        "    if the_type == 1:\n",
        "      return la_output.split(sep)[-1]\n",
        "    else:\n",
        "      return file_size\n",
        "  else:\n",
        "    print(la_output)\n",
        "\n",
        "def get_dir_size(path='.'):\n",
        "    total = 0\n",
        "    with os.scandir(path) as it:\n",
        "        for entry in it:\n",
        "            if entry.is_file():\n",
        "                total += entry.stat().st_size\n",
        "            elif entry.is_dir():\n",
        "                total += get_dir_size(entry.path)\n",
        "\n",
        "    return total\n",
        "\n",
        "\n",
        "\n",
        "def timenow():\n",
        "  from datetime import date as datetimedate, datetime, timedelta\n",
        "  import pytz\n",
        "  return datetime.now(pytz.timezone(\"Etc/GMT-6\")).strftime('%d %B %Y, %I:%M:%S %p')\n",
        "# timenow()\n",
        "def epoch_checker():\n",
        "  from matplotlib import pyplot as plt\n",
        "  train_loss = np.load(os.path.join(model_dir, 'loss_train.npy'))\n",
        "  train_metric = np.load(os.path.join(model_dir, 'metric_train.npy'))\n",
        "  test_loss = np.load(os.path.join(model_dir, 'loss_test.npy'))\n",
        "  test_metric = np.load(os.path.join(model_dir, 'metric_test.npy'))\n",
        "  fig,ax = plt.subplots(figsize=(6,12),nrows=2,ncols=1,)\n",
        "\n",
        "  a, = ax[0].plot(test_loss,'o-',label='test_loss')\n",
        "  b, = ax[0].plot(train_loss,'x--',label='train_loss')\n",
        "  # ax.grid()\n",
        "  ax[0].set_title('DICE loss')\n",
        "  ax[0].legend(handles=[a,b])\n",
        "  # plt.legend()\n",
        "  ax[0].grid()\n",
        "  # plt.subplot(2,1,2)\n",
        "\n",
        "  a, = ax[1].plot(test_metric,'o-',label='test_metric')\n",
        "  b, = ax[1].plot(train_metric,'x--',label='train_metric')\n",
        "\n",
        "  ax[1].legend(handles=[a,b])\n",
        "  ax[1].set_title('DICE metric')\n",
        "  plt.suptitle('\\n\\nepoch'+sep+str(len(train_loss))+'\\n'+timenow())\n",
        "  ax[1].grid()\n",
        "  # if os.path.exists(model_dir+'graphs/') is False:\n",
        "  #   os.mkdir(model_dir+'graphs/')\n",
        "  # plt.legend()\n",
        "\n",
        "  plt.savefig(model_dir+'graphs/'+timenow()+'.png',bbox_inches='tight')\n",
        "  # plt = 0\n",
        "\n",
        "# epoch_checker()"
      ],
      "metadata": {
        "id": "HxMb1iU5yJjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#THIS CODE BLOCK IS HOW WE TRAINED THE MODEL"
      ],
      "metadata": {
        "id": "cc3gZXweyn9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####THIS TAKES THE TENSORS DATA AND THEN TRAINS THE MODEL, AND THE DICE_METRIC AND CALCULATED WEIGHTS ARE THERE TO TUNE THE ERROR THRESHOLD OF THE MODELS OUTPUT\n",
        "\n",
        "def dice_metric(predicted, target):\n",
        "    '''\n",
        "    In this function we take `predicted` and `target` (label) to calculate the dice coeficient then we use it\n",
        "    to calculate a metric value for the training and the validation.\n",
        "    '''\n",
        "    dice_value = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
        "    value = 1 - dice_value(predicted, target).item()\n",
        "    return value\n",
        "\n",
        "def calculate_weights(val1, val2):\n",
        "    '''\n",
        "    In this function we take the number of the background and the forgroud pixels to return the `weights`\n",
        "    for the cross entropy loss values.\n",
        "    '''\n",
        "    count = np.array([val1, val2])\n",
        "    summ = count.sum()\n",
        "    weights = count/summ\n",
        "    weights = 1/weights\n",
        "    summ = weights.sum()\n",
        "    weights = weights/summ\n",
        "    return torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "def train(model, data_in, loss, optim, max_epochs, model_dir, test_interval=1 , device=torch.device(\"cuda:0\")):\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    try:\n",
        "      save_loss_train = list(np.load(os.path.join(model_dir, 'loss_train.npy')))\n",
        "      save_loss_test = list(np.load(os.path.join(model_dir, 'loss_test.npy')))\n",
        "      save_metric_train = list(np.load(os.path.join(model_dir, 'metric_train.npy')))\n",
        "      save_metric_test = list(np.load(os.path.join(model_dir, 'metric_test.npy')))\n",
        "    except FileNotFoundError:\n",
        "      save_loss_train = []\n",
        "      save_loss_test = []\n",
        "      save_metric_train = []\n",
        "      save_metric_test = []\n",
        "    train_loader, test_loader = data_in\n",
        "\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        # clear()\n",
        "        # try:\n",
        "        #   plt= 0\n",
        "        #   epoch_checker()\n",
        "        # except FileNotFoundError:\n",
        "        #   print('Not doing the EPOCH CHECKER')\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "\n",
        "        model.train()\n",
        "        try:\n",
        "          train_epoch_loss = save_loss_train[-1]\n",
        "          epoch_metric_train = save_metric_train[-1]\n",
        "        except IndexError:\n",
        "          train_epoch_loss = 0\n",
        "          epoch_metric_train = 0\n",
        "\n",
        "        train_step = 0\n",
        "\n",
        "        for batch_data in train_loader:\n",
        "            clear()\n",
        "            train_step += 1\n",
        "\n",
        "            volume = batch_data[\"vol\"]\n",
        "            label = batch_data[\"seg\"]\n",
        "            label = label != 0\n",
        "            volume, label = (volume.to(device), label.to(device))\n",
        "\n",
        "            optim.zero_grad()\n",
        "            outputs = model(volume)\n",
        "\n",
        "            train_loss = loss(outputs, label)\n",
        "\n",
        "            train_loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            train_epoch_loss += train_loss.item()\n",
        "            print(\n",
        "                f\"{train_step}/{len(train_loader) // train_loader.batch_size}, \"\n",
        "                f\"Train_loss: {train_loss.item():.4f}\")\n",
        "\n",
        "            train_metric = dice_metric(outputs, label)\n",
        "            epoch_metric_train += train_metric\n",
        "            print(f'Train_dice: {train_metric:.4f}')\n",
        "            !nvidia-smi\n",
        "            # time.sleep(1)\n",
        "            # clear()\n",
        "\n",
        "        clear()\n",
        "        print('-'*20)\n",
        "\n",
        "        train_epoch_loss /= train_step\n",
        "        print(f'Epoch_loss: {train_epoch_loss:.4f}')\n",
        "        save_loss_train.append(train_epoch_loss)\n",
        "        np.save(os.path.join(model_dir, 'loss_train.npy'), save_loss_train)\n",
        "\n",
        "        epoch_metric_train /= train_step\n",
        "        print(f'Epoch_metric: {epoch_metric_train:.4f}')\n",
        "\n",
        "        save_metric_train.append(epoch_metric_train)\n",
        "        np.save(os.path.join(model_dir, 'metric_train.npy'), save_metric_train)\n",
        "\n",
        "\n",
        "        if (epoch + 1) % test_interval == 0:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                try:\n",
        "                  test_epoch_loss = save_loss_test[-1]\n",
        "                  epoch_metric_test = save_metric_test[-1]\n",
        "                except IndexError:\n",
        "                  test_epoch_loss = 0\n",
        "                  epoch_metric_test = 0\n",
        "\n",
        "                test_metric = 0\n",
        "\n",
        "                test_step = 0\n",
        "\n",
        "                for test_data in test_loader:\n",
        "                    # clear()\n",
        "                    test_step += 1\n",
        "\n",
        "                    test_volume = test_data[\"vol\"]\n",
        "                    test_label = test_data[\"seg\"]\n",
        "                    test_label = test_label != 0\n",
        "                    test_volume, test_label = (test_volume.to(device), test_label.to(device),)\n",
        "\n",
        "                    test_outputs = model(test_volume)\n",
        "\n",
        "                    test_loss = loss(outputs, test_label)\n",
        "                    test_epoch_loss += test_loss.item()\n",
        "                    test_metric = dice_metric(test_outputs, test_label)\n",
        "                    epoch_metric_test += test_metric\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                test_epoch_loss /= test_step\n",
        "                print(f'test_loss_epoch: {test_epoch_loss:.4f}')\n",
        "\n",
        "                # clear()\n",
        "                save_loss_test.append(test_epoch_loss)\n",
        "                np.save(os.path.join(model_dir, 'loss_test.npy'), save_loss_test)\n",
        "\n",
        "                epoch_metric_test /= test_step\n",
        "                print(f'test_dice_epoch: {epoch_metric_test:.4f}')\n",
        "                save_metric_test.append(epoch_metric_test)\n",
        "                np.save(os.path.join(model_dir, 'metric_test.npy'), save_metric_test)\n",
        "                clear()\n",
        "                print('checking epoch...')\n",
        "                time.sleep(1)\n",
        "                epoch_checker()\n",
        "                clear()\n",
        "\n",
        "\n",
        "                if epoch_metric_test > best_metric:\n",
        "                    best_metric = epoch_metric_test\n",
        "                    best_metric_epoch = epoch + 1\n",
        "                    torch.save(model.state_dict(), os.path.join(\n",
        "                        model_dir, \"best_metric_model.pth\"))\n",
        "\n",
        "                print(\n",
        "                    f\"current epoch: {epoch + 1} current mean dice: {test_metric:.4f}\"\n",
        "                    f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                    f\"at epoch: {best_metric_epoch}\"\n",
        "                  )\n",
        "\n",
        "\n",
        "\n",
        "    print(\n",
        "        f\"train completed, best_metric: {best_metric:.4f} \"\n",
        "        f\"at epoch: {best_metric_epoch}\")\n",
        "\n",
        "\n",
        "\n",
        "def calculate_pixels(data):\n",
        "    val = np.zeros((1, 2))\n",
        "\n",
        "    for batch in tqdm(data):\n",
        "        batch_label = batch[\"seg\"] != 0\n",
        "        _, count = np.unique(batch_label, return_counts=True)\n",
        "\n",
        "        if len(count) == 1:\n",
        "            count = np.append(count, 0)\n",
        "        val += count\n",
        "\n",
        "    print('The last values:', val)\n",
        "    return val\n"
      ],
      "metadata": {
        "id": "wYwplFVTywr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PREDICTING LIVER MASK FOR TEST FILES WITHOUT SEGMENTATION ------- SELF EXPLANATORY\n",
        "#PREDICTING LIVER MASK FOR NEW FILES ---- TAKES IN IMAGES WITHIN THE TRAINING FOLDER THAT WERE NOT USED IN TRAINING.\n",
        "#SO AS FAR AS THE MODEL IS CONCERNED THOSE ARE NEW FILES, WE TEST THE MODELS OUTPUT AGAINST THE ACTUAL SEGMENTATION\n",
        "#AND VISUALLY WE TRY TO DETERMINE IF THE MODEL IS BEHAVING CORRECTLY.\n",
        "\n",
        "#SHOWS PROCESSED IMAGE PIPELINE FOR A RANDOM IMAGE -- SELF EXPLANATORY\n",
        "\n",
        "#CORRECTS THE ORIENTATION OF THE IMAGE\n",
        "def correct_orient(a):\n",
        "  a = np.fliplr(a)\n",
        "  a = np.rot90(a,3)\n",
        "  return a\n",
        "\n",
        "def predicting_liver_mask_for_test_files_without_segmentation(test_files,start_slice,end_slice,colormap='grey',model_path=main_path+'/MODELscratch/best_metric_model.pth'):\n",
        "# colormap = 'gray'\n",
        "  file_name = test_files[0]['vol'].split(tsvol)[-1]\n",
        "  print('Validating against',test_files[0]['vol'].split(trvol)[-1])\n",
        "  print('from slice',start_slice,'to',end_slice)\n",
        "\n",
        "\n",
        "  test_transforms = Compose(\n",
        "      [\n",
        "          LoadImaged(keys=[\"vol\", \"seg\"],allow_missing_keys=True),\n",
        "          AddChanneld(keys=[\"vol\", \"seg\"],allow_missing_keys=True),\n",
        "          Spacingd(keys=[\"vol\", \"seg\"],allow_missing_keys=True, pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "          Orientationd(keys=[\"vol\", \"seg\"],allow_missing_keys=True, axcodes=\"RAS\"),\n",
        "          ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True),\n",
        "          CropForegroundd(keys=['vol', 'seg'], source_key='vol',allow_missing_keys=True),\n",
        "          Resized(keys=[\"vol\", \"seg\"],allow_missing_keys=True, spatial_size=[128,128,64]),\n",
        "          ToTensord(keys=[\"vol\", \"seg\"],allow_missing_keys=True),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "\n",
        "  # test_ds = Dataset(data=test_files)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  device = torch.device(my_device)\n",
        "  model = UNet(\n",
        "      dimensions=3,\n",
        "      in_channels=1,\n",
        "      out_channels=2,\n",
        "      channels=(16, 32, 64, 128, 256),\n",
        "      strides=(2, 2, 2, 2),\n",
        "      num_res_units=2,\n",
        "      norm=Norm.BATCH,\n",
        "  ).to(device)\n",
        "  if model_path not in empty_list:\n",
        "    model.load_state_dict(torch.load(\n",
        "        model_path,map_location=torch.device(my_device)))\n",
        "    model.eval()\n",
        "\n",
        "  if model_path in empty_list:\n",
        "    model_path = '**no models were used**'\n",
        "  sw_batch_size = 4\n",
        "  roi_size = (128, 128, 64)\n",
        "  with torch.no_grad():\n",
        "      test_patient = first(test_loader)\n",
        "      t_volume = test_patient['vol']\n",
        "      # t_segmentation = test_patient['seg']\n",
        "\n",
        "      test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
        "      # tarp = test_outputs\n",
        "      sigmoid_activation = Activations(sigmoid=True)\n",
        "      test_outputs = sigmoid_activation(test_outputs)\n",
        "      # test_outputs = test_outputs > 0.997\n",
        "      test_outputs = test_outputs > .75\n",
        "      # import cv2\n",
        "      for i in range(start_slice,end_slice+1):\n",
        "          # plot the slice [:, :, 80]\n",
        "          processed_slice = test_patient[\"vol\"][0, 0, :, :, i].numpy()\n",
        "          # target = test_patient[\"seg\"][0, 0, :, :, i].numpy() > 0\n",
        "          target= np.ones([128,128],dtype='float32')\n",
        "          actual_slice = nibabel.load(tsvol+file_name).get_fdata()[:,:,i]\n",
        "          prediction = np.array(test_outputs.detach().cpu()[0,1,:,:,i],dtype='float32')\n",
        "          difference = np.array(np.logical_xor(processed_slice,prediction),dtype='float32')\n",
        "          # difference = 1-(2*(np.logical_and(target,prediction)/np.logical_or(target,prediction)))\n",
        "\n",
        "          processed_slice = correct_orient(processed_slice)\n",
        "          target = correct_orient(target)\n",
        "          actual_slice = correct_orient(actual_slice)\n",
        "          prediction = correct_orient(prediction)\n",
        "          difference = correct_orient(difference)\n",
        "\n",
        "          try:\n",
        "            accuracy = round((1-(abs(np.count_nonzero(difference))/np.count_nonzero(target)))*100,3)\n",
        "            print('xor accuracy:',accuracy)\n",
        "            # accuracy = round(dice_coef(prediction,target)*100,3)\n",
        "            accuracy = round(np.sum(prediction[target==1]*2.0/(np.sum(prediction)+np.sum(target)))*100,3)\n",
        "            print('dice coeff:',accuracy)\n",
        "\n",
        "          except ZeroDivisionError:\n",
        "            if np.count_nonzero(target)==0 and np.count_nonzero(prediction) != 0:\n",
        "              accuracy = 0\n",
        "            if np.count_nonzero(target)!=0  and np.count_nonzero(prediction) == 0:\n",
        "              accuracy = 0\n",
        "            if np.count_nonzero(target)==0 and np.count_nonzero(prediction) == 0:\n",
        "              accuracy = 100\n",
        "\n",
        "\n",
        "          # plt.rc('lines',linewidth=1.6)\n",
        "\n",
        "          fig, ax = plt.subplots(figsize=(30,12))\n",
        "          plt.rc('font',family='serif',size=35)\n",
        "          COLOR = [0,0,0]\n",
        "          # ax.tick_params(size=14)\n",
        "          # ax.yticks(fontsize=14)\n",
        "          plt.axis('on')\n",
        "          plt.rcParams['axes.labelcolor'] = COLOR\n",
        "          plt.rcParams['xtick.labelsize'] = 26\n",
        "          plt.rcParams['ytick.labelsize'] = 0\n",
        "          plt.rcParams['xtick.color'] = COLOR\n",
        "          plt.rcParams['ytick.color'] = COLOR\n",
        "\n",
        "          # plt.rcParams['text.color'] = [1,1,1]\n",
        "          plt.subplot(1,5,1)\n",
        "          plt.title(f\"SLICE\\n\")\n",
        "          plt.imshow(actual_slice,cmap=colormap)\n",
        "          plt.xticks([0,actual_slice.shape[0]])\n",
        "          plt.yticks([0,0])\n",
        "\n",
        "          plt.subplot(1, 5, 2)\n",
        "          plt.title(f\"PROCESSED\\nSLICE\")\n",
        "          plt.imshow(processed_slice,cmap=colormap)\n",
        "          plt.xticks([0,processed_slice.shape[0]])\n",
        "          plt.yticks([0, 0])\n",
        "\n",
        "          plt.subplot(1, 5, 4)\n",
        "          plt.title(f\"OVERLAY\\n\")\n",
        "          mask = prediction\n",
        "          plt.imshow(processed_slice,cmap=colormap)\n",
        "          plt.imshow(np.ma.masked_where(mask==0,mask),cmap='jet')\n",
        "\n",
        "\n",
        "          plt.xticks([0,processed_slice.shape[0]])\n",
        "          plt.yticks([0,0])\n",
        "\n",
        "          plt.subplot(1, 5, 3)\n",
        "          plt.title(f\"PREDICTION\\n\")\n",
        "          plt.imshow(prediction,cmap=colormap)\n",
        "          plt.xticks([0,prediction.shape[0]])\n",
        "          plt.yticks([0,0])\n",
        "\n",
        "          # clear()\n",
        "          plt.subplot(1,5,5)\n",
        "          plt.title(f\"SEGMENTED\\nPART\")\n",
        "          plt.imshow(processed_slice, cmap='gray', alpha=1.0*(prediction>0))\n",
        "          plt.xticks([0,processed_slice.shape[0]])\n",
        "          plt.yticks([0,0])\n",
        "          # plt.suptitle('TEST FILE: '+tsvol+file_name+'\\nSLICE NUMBER: '+str(i)+'\\n'+\n",
        "          #             'MODEL USED: '+model_path.split(main_path)[-1]+'\\n'+\n",
        "          #             'DEVICE: '+my_device.upper()+'\\n'+\n",
        "          #             # 'THRESHOLD: '+str(threshold_of_error)+' [0 --> 1]\\n'+\n",
        "          #             # 'ACCURACY: '+str(accuracy)+'%\\n'+\n",
        "          #             'TIMESTAMP: '+timenow(),ha='left',va='top',x=0.11,y=.89)\n",
        "          if accuracy > 10 and accuracy < 100:\n",
        "            # clear()\n",
        "            file_name = model_path.split(main_path)[-1].split('/')[2]+' [segmenting]'\n",
        "            print(file_name)\n",
        "            plt.savefig(main_path+'TESTED_DATA/'+file_name+sep+timenow()+'.png',bbox_inches='tight',dpi=600)\n",
        "            plt.show()\n",
        "            print('SAVED VALIDATION....')\n",
        "\n",
        "          # plt.savefig(main_path+'TESTED_DATA/TESTVOLUME '+timenow()+'.png',bbox_inches='tight',dpi=600)\n",
        "          # plt.show()\n",
        "          # print('SAVED VALIDATION....')\n",
        "\n",
        "\n",
        "#####THIS\n",
        "\n",
        "\n",
        "def predicting_liver_mask_for_new_files(file_index,start_slice,end_slice,colormap='gray',threshold_of_error=0.53,model_path=main_path+'/MODELscratch/best_metric_model.pth'):\n",
        "\n",
        "\n",
        "  my_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print('CHOOSING',my_device,'to do the validation')\n",
        "\n",
        "  in_dir = traindir\n",
        "\n",
        "  path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))[0:index]\n",
        "  path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))[0:index]\n",
        "\n",
        "  path_test_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))[index:]\n",
        "  path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))[index:]\n",
        "\n",
        "  train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
        "  test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
        "  # test_files = test_files\n",
        "  # print(test_files)\n",
        "  # test_files = [{'vol':tsvol+'liver_132_0.nii.gz','seg':trseg+'liver_0_0.nii.gz'}]\n",
        "\n",
        "  test_files = test_files[file_index-1:file_index]\n",
        "  file_name = test_files[0]['vol'].split(trvol)[-1]\n",
        "  print('Validating against',test_files[0]['vol'].split(trvol)[-1])\n",
        "  print('from slice',start_slice,'to',end_slice)\n",
        "\n",
        "\n",
        "  test_transforms = Compose(\n",
        "      [\n",
        "          LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "          AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "          Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "          Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "          ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True),\n",
        "          CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "          Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),\n",
        "          ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "\n",
        "  # test_ds = Dataset(data=test_files)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  device = torch.device(my_device)\n",
        "  model = UNet(\n",
        "      dimensions=3,\n",
        "      in_channels=1,\n",
        "      out_channels=2,\n",
        "      channels=(16, 32, 64, 128, 256),\n",
        "      strides=(2, 2, 2, 2),\n",
        "      num_res_units=2,\n",
        "      norm=Norm.BATCH,\n",
        "  ).to(device)\n",
        "  if model_path not in empty_list:\n",
        "    model.load_state_dict(torch.load(\n",
        "        model_path,map_location=torch.device(my_device)))\n",
        "    model.eval()\n",
        "\n",
        "  if model_path in empty_list:\n",
        "    model_path = '**no models were used**'\n",
        "  sw_batch_size = 4\n",
        "  roi_size = (128, 128, 64)\n",
        "  with torch.no_grad():\n",
        "      test_patient = first(test_loader)\n",
        "      t_volume = test_patient['vol']\n",
        "      t_segmentation = test_patient['seg']\n",
        "\n",
        "      test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
        "      # tarp = test_outputs\n",
        "      sigmoid_activation = Activations(sigmoid=True)\n",
        "      test_outputs = sigmoid_activation(test_outputs)\n",
        "      # test_outputs = test_outputs > 0.997\n",
        "      test_outputs = test_outputs > .75\n",
        "      # import cv2\n",
        "      for i in range(start_slice,end_slice+1):\n",
        "          # plot the slice [:, :, 80]\n",
        "          processed_slice = test_patient[\"vol\"][0, 0, :, :, i].numpy()\n",
        "          target = test_patient[\"seg\"][0, 0, :, :, i].numpy() > 0\n",
        "          actual_slice = nibabel.load(trvol+file_name).get_fdata()[:,:,i]\n",
        "          prediction = np.array(test_outputs.detach().cpu()[0,1,:,:,i],dtype='float32')\n",
        "          difference = np.array(np.logical_xor(prediction,target),dtype='float32')\n",
        "          # difference = 1-(2*(np.logical_and(target,prediction)/np.logical_or(target,prediction)))\n",
        "\n",
        "\n",
        "          processed_slice = correct_orient(processed_slice)\n",
        "          target = correct_orient(target)\n",
        "          actual_slice = correct_orient(actual_slice)\n",
        "          prediction = correct_orient(prediction)\n",
        "          difference = correct_orient(difference)\n",
        "\n",
        "          try:\n",
        "            accuracy = round((1-(abs(np.count_nonzero(difference))/np.count_nonzero(target)))*100,3)\n",
        "            print('xor accuracy:',accuracy)\n",
        "            # accuracy = round(dice_coef(prediction,target)*100,3)\n",
        "            accuracy = round(np.sum(prediction[target==1]*2.0/(np.sum(prediction)+np.sum(target)))*100,3)\n",
        "            print('dice coeff:',accuracy)\n",
        "\n",
        "          except ZeroDivisionError:\n",
        "            if np.count_nonzero(target)==0 and np.count_nonzero(prediction) != 0:\n",
        "              accuracy = 0\n",
        "            if np.count_nonzero(target)!=0  and np.count_nonzero(prediction) == 0:\n",
        "              accuracy = 0\n",
        "            if np.count_nonzero(target)==0 and np.count_nonzero(prediction) == 0:\n",
        "              accuracy = 100\n",
        "\n",
        "\n",
        "          # plt.rc('lines',linewidth=1.6)\n",
        "\n",
        "          fig, ax = plt.subplots(figsize=(30,12))\n",
        "          plt.rc('font',family='serif',size=35)\n",
        "          COLOR = [0,0,0]\n",
        "          # ax.tick_params(size=14)\n",
        "          # ax.yticks(fontsize=14)\n",
        "          plt.axis('on')\n",
        "          plt.rcParams['axes.labelcolor'] = COLOR\n",
        "          plt.rcParams['xtick.labelsize'] = 26\n",
        "          plt.rcParams['ytick.labelsize'] = 0\n",
        "          plt.rcParams['xtick.color'] = COLOR\n",
        "          plt.rcParams['ytick.color'] = COLOR\n",
        "\n",
        "          plt.subplot(1,5,1)\n",
        "          plt.title(f\"SLICE\\n\")\n",
        "          plt.imshow(actual_slice,cmap=colormap)\n",
        "          plt.xticks([0, actual_slice.shape[0]])\n",
        "          plt.yticks([0, actual_slice.shape[0]])\n",
        "\n",
        "          plt.subplot(1, 5, 2)\n",
        "          plt.title(f\"PROCESSED\\nSLICE\")\n",
        "          plt.imshow(processed_slice,cmap=colormap)\n",
        "          plt.xticks([0, processed_slice.shape[0]])\n",
        "          plt.yticks([0, 0])\n",
        "\n",
        "          plt.subplot(1, 5, 3)\n",
        "          plt.title(f\"TARGET\\n\")\n",
        "          plt.imshow(target,cmap=colormap)\n",
        "          plt.xticks([0, target.shape[0]])\n",
        "          plt.yticks([0, 0])\n",
        "          # plt.imshow(nibabel.load(test_files[0]['seg']).get_fdata()[:,:,i])\n",
        "          plt.subplot(1, 5, 4)\n",
        "          plt.title(f\"PREDICTION\\n\")\n",
        "          plt.imshow(prediction,cmap=colormap)\n",
        "          plt.xticks([0, prediction.shape[0]])\n",
        "          plt.yticks([0, 0])\n",
        "\n",
        "          # clear()\n",
        "          plt.subplot(1,5,5)\n",
        "          plt.title(f\"DIFFERENCE\\n\")\n",
        "          plt.imshow(difference,cmap=colormap)\n",
        "          plt.xticks([0, difference.shape[0]])\n",
        "          plt.yticks([0, 0])\n",
        "          # plt.suptitle('TEST FILE: '+file_name+'\\nSLICE NUMBER: '+str(i)+'\\n'+\n",
        "          #             'MODEL USED: '+model_path.split(main_path)[-1]+'\\n'+\n",
        "          #             'DEVICE: '+my_device.upper()+'\\n'+\n",
        "          #             'THRESHOLD: '+str(threshold_of_error)+' [0 --> 1]\\n'+\n",
        "          #             'ACCURACY: '+str(accuracy)+'%\\n'+\n",
        "          #             'TIMESTAMP: '+timenow(),ha='left',va='top',x=0.11,y=.92)\n",
        "\n",
        "\n",
        "          if accuracy > 88 and accuracy < 100:\n",
        "            # clear()\n",
        "            file_name = model_path.split(main_path)[-1].split('/')[2]\n",
        "            print(file_name)\n",
        "            plt.savefig(main_path+'TESTED_DATA/'+file_name+sep+timenow()+'.png',bbox_inches='tight',dpi=600)\n",
        "            plt.show()\n",
        "            print('SAVED VALIDATION....')\n",
        "\n",
        "##############JUST PLOTTING\n",
        "\n",
        "### JUST FOR VISUAL REPRESENTATION.  WE ARE SHOWING HOW THE INDIVIDUAL IMAGES ARE PREPROCESSED IN ORDER TO BEST SUIT THE MODEL.\n",
        "\n",
        "def shows_processed_image_pipeline_for_a_random_image():\n",
        "  import numpy as np, nibabel\n",
        "  from matplotlib import pyplot as plt\n",
        "  from monai.transforms import(\n",
        "      Compose,\n",
        "      AddChanneld,\n",
        "      LoadImaged,\n",
        "      Resized,\n",
        "      ToTensord,\n",
        "      Spacingd,\n",
        "      Orientationd,\n",
        "      ScaleIntensityRanged,\n",
        "      CropForegroundd,\n",
        "  )\n",
        "  from monai.data import DataLoader, Dataset, CacheDataset\n",
        "  from monai.utils import set_determinism\n",
        "  from monai.utils import first\n",
        "  in_dir = traindir\n",
        "  main_path = '/content/drive/MyDrive/thesis_dataset/'\n",
        "  livpath = main_path+'Liver/Task03_Liver/'\n",
        "  mypath = main_path+'test_path/'\n",
        "  trpath = main_path+'imagesTr_path'\n",
        "  labels = main_path+'labels_path'\n",
        "  tspath = main_path+'imagesTs_path'\n",
        "  folder = 'imagesTr'\n",
        "  sixtyfournifties = main_path+'groups_of_64_nifti/'+folder+'/'\n",
        "\n",
        "\n",
        "\n",
        "  inc = 0\n",
        "  index = np.random.randint(0,366)\n",
        "\n",
        "  slice_number1 = np.random.randint(0,64)\n",
        "  # print(index,file_index,slice_number1)\n",
        "\n",
        "\n",
        "  path_test_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))[index:]\n",
        "  path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))[index:]\n",
        "  test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
        "\n",
        "  file_index = np.random.randint(0,len(test_files)-1)\n",
        "  test_files = test_files[file_index-1:file_index]\n",
        "  file_name1 = test_files[0]['vol']\n",
        "\n",
        "\n",
        "  # file_name1\n",
        "\n",
        "  slice_number = int(file_name1.split('.nii.gz')[0].split('_')[-1])*64+slice_number1\n",
        "\n",
        "\n",
        "  # files = os.listdir(sixtyfournifties)\n",
        "  test_image1 = nibabel.load(file_name1).get_fdata()\n",
        "  # test_image2 = nibabel.load(file_name2).get_fdata()\n",
        "  test_image1 = correct_orient(test_image1)\n",
        "  # test_files = [{'vol':file_name1,'seg':file_name1.replace('Volumes','Segmentation')}]\n",
        "\n",
        "  plt = ''\n",
        "  ax = ''\n",
        "  fig = ''\n",
        "  from matplotlib import pyplot as plt\n",
        "\n",
        "  fig,ax = plt.subplots(figsize=(23,14))\n",
        "\n",
        "  plt.rc('font',family='serif',size=35)\n",
        "  COLOR = [0,0,0]\n",
        "  # ax.tick_params(size=14)\n",
        "  # ax.yticks(fontsize=14)\n",
        "  # plt.axis('on')\n",
        "  plt.rcParams['axes.labelcolor'] = COLOR\n",
        "  plt.rcParams['xtick.labelsize'] = 26\n",
        "  plt.rcParams['ytick.labelsize'] = 0\n",
        "  plt.rcParams['xtick.color'] = COLOR\n",
        "  plt.rcParams['ytick.color'] = COLOR\n",
        "\n",
        "\n",
        "  plt.subplot(2,4,1)\n",
        "\n",
        "  str0 = '1. Loading\\nSlice'\n",
        "  plt.imshow(test_image1[:,:,slice_number1],cmap='gray')\n",
        "  plt.xticks([0, test_image1.shape[0]])\n",
        "  plt.yticks([0, test_image1.shape[0]-1])\n",
        "  plt.title(str0)\n",
        "\n",
        "\n",
        "  str1 = '2. Adding an\\nextra channel'\n",
        "  plt_number = 2\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            # Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            # Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            # ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True),\n",
        "            # CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            # Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "\n",
        "  str1 = '3. Bilinear\\nSpacing'\n",
        "  plt_number = 3\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            # Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            # ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True),\n",
        "            # CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            # Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "  str1 = '4. Correcting\\nOrientation'\n",
        "  plt_number = 4\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            # ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True),\n",
        "            # CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            # Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "  str1 = '5. Scaling\\nIntensity'\n",
        "  plt_number = 5\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True),\n",
        "            # CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            # Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "  str1 = '6. Croping\\nForeground'\n",
        "  plt_number = 6\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            # Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  a,b = test_image2.shape\n",
        "\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  # plt.xticks([0, test_image2.shape[1]])\n",
        "  # plt.yticks([test_image2.shape[0]-1-test_image2.shape[1], test_image2.shape[0]-1])\n",
        "  plt.xticks([0,a])\n",
        "  plt.yticks([test_image2.shape[0]-1-b,test_image2.shape[0]-1])\n",
        "  str1 = '7. Resizing\\n'\n",
        "  plt_number = 7\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "  str1 = '8. Processed\\nSlice'\n",
        "  plt_number = 8\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "  # plt.suptitle('Processing '+file_name1.split(trvol)[-1]+' at slice number '+str(slice_number1))\n",
        "  plt.savefig(main_path+'TESTED_DATA/PREPROCESSING IMAGE '+timenow()+'.png',bbox_inches='tight',dpi=600)\n",
        "  plt.show()\n",
        "  print('SAVED PREP....')\n",
        "  plt.show()\n",
        "\n",
        "  # return accuracy"
      ],
      "metadata": {
        "id": "9OpTRnlKy9j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pee6m0Y9cvtH"
      },
      "source": [
        "CTRL+START\n",
        "#ORGAN SEGMENTATION (LIVER) OF 3D MEDICAL IMAGES USING PYTORCH & MONAI\n",
        "###GROUP 4, Md. Salim Shahed Shajid [2017338016], MD. Ashraf Hossain Ifty [2017338042]\n",
        "\n",
        "thesis_database folder: https://drive.google.com/drive/folders/1VBjfxsrTDK6jChNYg4QCVIurLydUP0fB\n",
        "\n",
        "Add this folder as a shortcut in the root folder 'My Drive.'\n",
        "\n",
        "#FOLDERS OF INTEREST\n",
        "####TRAINER -- contains the data for training and testing.\n",
        "####TESTED_DATA -- contains the validation of the models.\n",
        "\n",
        "#MODEL folders\n",
        "1. MODEL\n",
        "2. MODELscratch\n",
        "3. MODELscratch_2\n",
        "\n",
        "\n",
        "#Summary\n",
        "\n",
        "Dataset from the Decathlon medical image website [http://medicaldecathlon.com/] was collected. It is the Task03_Liver.tar in the folder. Data were extracted [thesis_database/Liver] and then because of uneven slices for each CT scan file [thesis_database/imagesTr_path], we sliced the standalone files in packets of 64 sliced nifti files [.nii.gz]. The segmented slices [thesis_database/labels_path] were also packeted in a similar fashion.\n",
        "After this, we discarded the nifti files that had no segmentation [the corresponding labels file had no data] and put them in the TRAINER folder. The actual slices were copied to the [thesis_database/TRAINER/TrainVolumes] folder, and the segmentation [labels] were copied to the [thesis_database/TRAINER/TrainSegmentation] folder.\n",
        "\n",
        "Then we took files from the TrainVolumes folder, and processed them further to make the training less time consuming. The processing part was to resize the image from [512,512] pixel to [128,128], the foreground [pixels with significant data] and background [pixels with not enough data] were saturated, the orientation was normalized in a consistent permutation i.e. RAS orientation. Then, the image's voxel width and height, were changed to 1.5 to make the processing faster and we further contrasted the images foreground to make the features more prominent.\n",
        "\n",
        "We split the TrainVolume data into random slices for Training and Testing the models accuracy. After that the data were cached into the gpu memory for faster training time, and now, we have a few trained models at various epochs.\n",
        "\n",
        "In the validation part of this system, the model takes in the processed image and predicts a mask where the liver should be. We compare this prediction with the actual label and determine how accurate the prediction was. The comparism is a simple XOR operation between the two images. So, when both pixel value is 1, the result is 0. This why we find the inaccuracy of the prediction and the target.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###BEFORE DOING ANYTHING, BTRL+F8, TO RUN ABOVE CELLS AND THEN RUN THIS CELL\n",
        "###AND MOUNT DRIVE\n",
        "###TO SEE IF EVERYTHING IS IN ORDER\n",
        "###TRAINER FOLDER CANNOT BE 0 BYTES\n",
        "dont_check = ['Liver','imagesTr_path','imagesTs_path','kaggler',\n",
        "              'labels_path','groups_of_64','groups_of_64_nifti','groups_of_64_nifti_non_empty','model_results','fusemachine kaggle']\n",
        "for files in os.listdir(main_path):\n",
        "  if files not in dont_check:\n",
        "    try:\n",
        "      print(files,sep,format_size(get_dir_size(main_path+files)))\n",
        "    except NotADirectoryError:\n",
        "      getfilesize(main_path+files,'')\n",
        "    # print(files)\n"
      ],
      "metadata": {
        "id": "wDosydL70drD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STARTING POINT,\n",
        "#RUN THIS CELL TO LOAD ALL THE DATA IN THE MEMORY FOR FASTER TRAINING\n",
        "#YOU WILL GET RUNTIMEERROR THE FIRST TIME, JUST RE-RUN THIS CELL\n",
        "#AND AFTER THE DATA IS LOADED ONTO THE MEMORY RUN THE NEXT CELL TO TRAIN THE MODEL\n",
        "\n",
        "from monai.networks.nets import UNet\n",
        "import sys\n",
        "\n",
        "from monai.networks.layers import Norm\n",
        "from monai.losses import DiceLoss, DiceCELoss\n",
        "import torch\n",
        "\n",
        "#########################NOTEBOOKS IN PARALLEL OPERATION#############ONLY CHANGE THESE VARIABLES CLONE NUMBER FROM 1 TO 5, AND DESIRED EPOCHS\n",
        "CLONE_NUMBER = 1\n",
        "epochs = 100\n",
        "########################################################\n",
        "\n",
        "\n",
        "model_dir = kfold+'DATA_FOLD_'+str(CLONE_NUMBER)+'/'\n",
        "\n",
        "print(model_dir)\n",
        "\n",
        "size = 128\n",
        "data_caches_for_different_kfold_splits = []\n",
        "\n",
        "train_files = sorted(glob(os.path.join(data_dir,\"TrainVolumes\",\"*.nii.gz\")))\n",
        "# train_files = sorted(os.listdir(data_dir+'TrainVolumes'))\n",
        "train_files_segmentation = sorted(glob(os.path.join(data_dir,\"TrainSegmentation\",\"*.nii.gz\")))\n",
        "\n",
        "kfold_database = to_json({},'kfold_database','read')['FOLD_'+str(CLONE_NUMBER)]\n",
        "\n",
        "kfold_train = [int(x) for x in kfold_database['kfold_train'].split(', ')]\n",
        "\n",
        "kfold_test = [int(x) for x in kfold_database['kfold_test'].split(', ')]\n",
        "\n",
        "if os.path.exists(model_dir+'graphs/') is False:\n",
        "  os.mkdir(model_dir+'graphs/')\n",
        "\n",
        "try:\n",
        "  epoch_done = len(np.load(model_dir+'loss_train.npy'))\n",
        "except Exception as e:\n",
        "  epoch_done = 0\n",
        "\n",
        "\n",
        "try:\n",
        "  print(data_in)\n",
        "\n",
        "except NameError:\n",
        "\n",
        "\n",
        "  if epochs-epoch_done >0:\n",
        "    data_in = prepare(data_dir, kfold_train, kfold_test,cache=True,spatial_size=[size,size,64])  #### THIS ONE TAKES DATA IN THE CACHE, TO MAKE THE TRAINING FAST\n",
        "    clone_k = CLONE_NUMBER\n",
        "\n",
        "if clone_k != CLONE_NUMBER and epochs-epoch_done>0:\n",
        "  data_in = prepare(data_dir, kfold_train, kfold_test,cache=True,spatial_size=[size,size,64])  #### THIS ONE TAKES DATA IN THE CACHE, TO MAKE THE TRAINING FAST\n",
        "  clone_k = CLONE_NUMBER\n",
        "\n",
        "print(model_dir)"
      ],
      "metadata": {
        "id": "CNqiB6VS0eov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ACTUAL TRAINER, DOESNT MATTER IF TRAINING GETS INTERRUPTED, IT WILL DO THE TRAIN FROM THE\n",
        "#NEXT EPOCH, AS LONG AS NOTHING IS TOUCHED HERE\n",
        "device = torch.device(my_device)\n",
        "learn_rate =  1e-5\n",
        "\n",
        "model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=2,\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    num_res_units=2,\n",
        "    norm=Norm.BATCH,\n",
        ").to(device)\n",
        "go = ''\n",
        "if os.path.exists(model_dir+'best_metric_model.pth'):\n",
        "  print('RESUMING FROM MODEL'+sep+model_dir.split('/')[-2])\n",
        "  model.load_state_dict(torch.load(\n",
        "        os.path.join(model_dir, \"best_metric_model.pth\"),map_location=torch.device(my_device)))#### to resume for a specific model\n",
        "\n",
        "  print(epoch_done,'epochs done.......')\n",
        "  if epochs-epoch_done > 0:\n",
        "    print('Remaining epochs',epochs-epoch_done)\n",
        "\n",
        "    # model.eval()\n",
        "    go='1'\n",
        "else:\n",
        "  go = '1'\n",
        "  epoch_done = 0\n",
        "\n",
        "# loss_function = DiceCELoss(to_onehot_y=True, sigmoid=True, squared_pred=True, ce_weight=calculate_weights(3.32088658e+08, 2.54757580e+07).to(device))\n",
        "loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-5, weight_decay=1e-5, amsgrad=True)\n",
        "\n",
        "if go not in empty_list:\n",
        "  print('STARTING TRAINING IN 5 SECONDS....')\n",
        "  time.sleep(5)\n",
        "  train(model, data_in, loss_function, optimizer, epochs-epoch_done, model_dir)\n",
        "# except ZeroDivisionError:\n",
        "#   clear()\n",
        "#   train(model, data_in, loss_function, optimizer, 600, model_dir)"
      ],
      "metadata": {
        "id": "HsV-Xduo0p5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####DELETE (FAULTY) EPOCH INDEX\n",
        "CL_NUMBER = 5\n",
        "fault_in_the_last = 0\n",
        "delete = 0 ################################### MAKE SURE THIS IS ALWAYS 0\n",
        "\n",
        "\n",
        "model_dir = kfold+'/DATA_FOLD_'+str(CL_NUMBER)+'/'\n",
        "\n",
        "if delete == 85695436:\n",
        "  delete_confirm = 1\n",
        "  files = ['loss_train','metric_train','loss_test','metric_test']\n",
        "else:\n",
        "  files = ['loss_train']\n",
        "  delete_confirm = ''\n",
        "\n",
        "\n",
        "for f in files:\n",
        "  if fault_in_the_last == 0:\n",
        "\n",
        "    a = np.load(model_dir+f+'.npy')\n",
        "  else:\n",
        "    a = np.load(model_dir+f+'.npy')[0:-fault_in_the_last]\n",
        "\n",
        "\n",
        "  if delete_confirm == 1:\n",
        "    print('reforming',model_dir+f+'.npy')\n",
        "    np.save(model_dir+f+'.npy',arr=a)\n",
        "\n",
        "\n",
        "  print(a,'\\n')\n",
        "\n",
        "  print(len(a))\n",
        "  print('-------------------')\n",
        "\n"
      ],
      "metadata": {
        "id": "P8_vthr10syY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#only the functions in this notebook are necessary, the other codes were just to visualize the data. or to segment the files to various folders for ease of use. to see those go to:\n",
        "\n",
        "##https://colab.research.google.com/drive/1VCMNqVPn8XP3Onmvf2ZAjEh1vogZqfK6"
      ],
      "metadata": {
        "id": "hv6-wjD_09-Q"
      }
    }
  ]
}